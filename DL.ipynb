{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "provenance": [],
      "mount_file_id": "1FieGX6YXvEQzhg5D9dETqqItjk2KI0Rt",
      "authorship_tag": "ABX9TyOnOB49esLE68qa1TIfd1Dg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AzusaFighting/DVdata/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UY4qrxQAh74",
        "outputId": "3e769bd7-6e89-4b3f-f155-c52115d4a3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.6.0.tar.gz (310 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 310 kB 8.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gpytorch\n",
            "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpytorch: filename=gpytorch-1.6.0-py2.py3-none-any.whl size=509889 sha256=20e842f6f671f1eb7a3c5e59ad0867d7feae5762305031e1a2388ed0cb76096b\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/b5/89/34c06ad393a6feb72b4cdde46d0f1c667f3e2632960f9df109\n",
            "Successfully built gpytorch\n",
            "Installing collected packages: gpytorch\n",
            "Successfully installed gpytorch-1.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install gpytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gpytorch"
      ],
      "metadata": {
        "id": "kJeUwHLBDW6k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word2ket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUa0vuR_EEaR",
        "outputId": "14ddc051-6e1b-4f25-fe82-229f86891592"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2ket\n",
            "  Downloading word2ket-0.0.2-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.7/dist-packages (from word2ket) (1.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from word2ket) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->word2ket) (4.2.0)\n",
            "Installing collected packages: word2ket\n",
            "Successfully installed word2ket-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import word2ket"
      ],
      "metadata": {
        "id": "J_kDTS4oEHQh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examples/demo.py \n",
        "from word2ket import EmbeddingKet, EmbeddingKetXS, ketify, summary\n",
        "from torch import nn\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "\n",
        "# Word2Ket Embedding Layer\n",
        "w2v_embedding_layer = EmbeddingKetXS(num_embeddings=30000, embedding_dim=256, order=4, rank=1)\n",
        "summary(w2v_embedding_layer)\n",
        "\"\"\"\n",
        "INFO:root:EmbeddingKetXS num_embeddings_leaf: 14\n",
        "INFO:root:EmbeddingKetXS embedding_dim_leaf: 4\n",
        "INFO:root:EmbeddingKetXS weight_leafs shape: torch.Size([4, 1, 14, 4])\n",
        "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
        "EmbeddingKetXS(30000, 256)                                                            1                 1                    224                                     \n",
        "Total number of trainable parameters elements 224\n",
        "\"\"\"\n",
        "\n",
        "# PyTorch Embedding Layer\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.embedding()\n",
        "model = MyModel(vocab_size=30000, embedding_dim=256)\n",
        "print(\"embedding.weight.shape: \", model.embedding.weight.shape)\n",
        "\"\"\"\n",
        "embedding.weight.shape:  torch.Size([30000, 256])\n",
        "\"\"\"\n",
        "summary(model)\n",
        "\"\"\"\n",
        "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
        "Embedding(30000, 256)                                                                 1                 1                    7,680,000                               \n",
        "Total number of trainable parameters elements 7,680,000\n",
        "\"\"\"\n",
        "\n",
        "# Replace the nn.Embedding to EmbeddingKetXS automatically using the ketify function.\n",
        "ketify(model, order=4, rank=2, use_EmbeddingKetXS=True)\n",
        "summary(model)\n",
        "\"\"\"\n",
        "INFO:root:EmbeddingKetXS num_embeddings_leaf: 14\n",
        "INFO:root:EmbeddingKetXS embedding_dim_leaf: 4\n",
        "INFO:root:EmbeddingKetXS weight_leafs shape: torch.Size([4, 2, 14, 4])\n",
        "INFO:root:Replaced embedding in MyModel\n",
        "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
        "EmbeddingKetXS(30000, 256)                                                            1                 1                    448                                     \n",
        "Total number of trainable parameters elements 448\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "BKx8noIDEOiT",
        "outputId": "48978193-f0e7-4c79-c9f8-724f835606e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:EmbeddingKetXS num_embeddings_leaf: 14\n",
            "INFO:root:EmbeddingKetXS embedding_dim_leaf: 4\n",
            "INFO:root:EmbeddingKetXS weight_leafs shape: torch.Size([4, 1, 14, 4])\n",
            "INFO:root:EmbeddingKetXS num_embeddings_leaf: 14\n",
            "INFO:root:EmbeddingKetXS embedding_dim_leaf: 4\n",
            "INFO:root:EmbeddingKetXS weight_leafs shape: torch.Size([4, 2, 14, 4])\n",
            "INFO:root:Replaced embedding in MyModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "EmbeddingKetXS(30000, 256)                                                            1                 1                    224                                     \n",
            "Total number of trainable parameters elements 224\n",
            "embedding.weight.shape:  torch.Size([30000, 256])\n",
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Embedding(30000, 256)                                                                 1                 1                    7,680,000                               \n",
            "Total number of trainable parameters elements 7,680,000\n",
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "EmbeddingKetXS(30000, 256)                                                            1                 1                    448                                     \n",
            "Total number of trainable parameters elements 448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nINFO:root:EmbeddingKetXS num_embeddings_leaf: 14\\nINFO:root:EmbeddingKetXS embedding_dim_leaf: 4\\nINFO:root:EmbeddingKetXS weight_leafs shape: torch.Size([4, 2, 14, 4])\\nINFO:root:Replaced embedding in MyModel\\nModule Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \\nEmbeddingKetXS(30000, 256)                                                            1                 1                    448                                     \\nTotal number of trainable parameters elements 448\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vODtC4YFHo0c",
        "outputId": "cd529875-3f88-4579-a9ca-5b172f233aea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive/prepare_data.py'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcAY3TVNLif7",
        "outputId": "3341ace5-e5b3-44ed-e94e-ff4ad6ec0cfe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install texar-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMjp0ouwLya9",
        "outputId": "d767ca45-b63e-4242-af95-9eac3230d735"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting texar-pytorch\n",
            "  Downloading texar_pytorch-0.1.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (1.21.6)\n",
            "Collecting mypy-extensions\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (1.15.0)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (21.3)\n",
            "Collecting asyml-utilities>=0.0.1.dev1\n",
            "  Downloading asyml_utilities-0.0.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (2.23.0)\n",
            "Requirement already satisfied: regex>=2018.01.10 in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=19.0->texar-pytorch) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (1.24.3)\n",
            "Installing collected packages: sentencepiece, mypy-extensions, funcsigs, asyml-utilities, texar-pytorch\n",
            "Successfully installed asyml-utilities-0.0.2 funcsigs-1.0.2 mypy-extensions-0.4.3 sentencepiece-0.1.96 texar-pytorch-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import texar.torch as tx\n",
        "\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--data', type=str, default=\"giga\", help=\"[giga|iwslt14]\")\n",
        "args = parser.parse_args()\n",
        "FLAGS_data = args.data\n",
        "\n",
        "def prepare_data():\n",
        "    \"\"\"Downloads data.\n",
        "    \"\"\"\n",
        "    if FLAGS_data == 'giga':\n",
        "        tx.data.maybe_download(\n",
        "            urls='https://drive.google.com/file/d/'\n",
        "                 '12RZs7QFwjj6dfuYNQ_0Ah-ccH1xFDMD5/view?usp=sharing',\n",
        "            path='./',\n",
        "            filenames='giga.zip',\n",
        "            extract=True)\n",
        "    elif FLAGS_data == 'iwslt14':\n",
        "        tx.data.maybe_download(\n",
        "            urls='https://drive.google.com/file/d/'\n",
        "                 '1y4mUWXRS2KstgHopCS9koZ42ENOh6Yb9/view?usp=sharing',\n",
        "            path='./',\n",
        "            filenames='iwslt14.zip',\n",
        "            extract=True)\n",
        "    else:\n",
        "        raise ValueError('Unknown data: {}'.format(FLAGS_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "6NWcIzfCJcLq",
        "outputId": "578c1dea-e686-4a41-dd1b-4f63d8e23506"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--data DATA]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-5f9f2e72-6898-46eb-adb2-695f1ab35c5e.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "70C1cPDQIxh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "Rt-gYvClIyC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9H0P9eG9EaC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}